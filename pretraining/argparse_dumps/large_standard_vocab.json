{
  "batch_div": 1,
  "name": "large_standard_vocab",
  "txt_file": "brwac_512.txt",
  "model_size": "large",
  "nepoch": 1.0,
  "seq_len": 512,
  "pre_trained_dir": "gs://t5-data/pretrained_models"
}{
  "batch_div": 1,
  "name": "large_standard_vocab",
  "txt_file": "brwac_512.txt",
  "model_size": "large",
  "nepoch": 1.0,
  "seq_len": 512,
  "pre_trained_dir": "gs://ptt5-1/large_standard_vocab/models/",
  "json_config_path": "../assin/T5_configs_json/ptt5-standard-vocab-large-config.json"
}
# O treino acima foi interrompido porque a m√quina caiu, coloquei de novo pra rodar o resto

{
  "batch_div": 1,
  "name": "large_standard_vocab",
  "txt_file": "brwac_512.txt",
  "model_size": "large",
  "nepoch": 0.25,
  "seq_len": 512,
  "pre_trained_dir": "gs://ptt5-1/large_standard_vocab/models/",
  "json_config_path": "../assin/T5_configs_json/ptt5-standard-vocab-large-config.json"
}
# Nao calculei certo quanto precisava rodar a mais e precisei colocar de novo
{
  "batch_div": 1,
  "name": "large_standard_vocab",
  "txt_file": "brwac_512.txt",
  "model_size": "large",
  "nepoch": 0.27,
  "seq_len": 512,
  "pre_trained_dir": "gs://ptt5-1/large_standard_vocab/models/",
  "json_config_path": "../../assin/T5_configs_json/ptt5-standard-vocab-large-config.json"
}